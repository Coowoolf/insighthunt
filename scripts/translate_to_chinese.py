#!/usr/bin/env python3
"""
InsightHunt Chinese Translation Script
Translates methodology content to professional PM-quality Chinese
"""

import os
import json
import time
import re
from pathlib import Path
from anthropic import Anthropic

# Configuration
DATA_DIR = Path("data/extracted/json")
DICT_FILE = Path("scripts/pm_terminology_dict.json")

# Use local Anthropic proxy (same as batch_pipeline.py)
client = Anthropic(
    api_key="sk-cbb33b67c7f14a208a67aa705ebf80ee",
    base_url="http://127.0.0.1:8045",
)
MODEL = "gemini-3-pro-high"

# Load PM terminology dictionary
with open(DICT_FILE, 'r', encoding='utf-8') as f:
    PM_DICT = json.load(f)

def create_translation_prompt(content_type: str, content: str, methodology_name: str) -> str:
    """Create a high-quality PM translation prompt"""
    
    terminology_examples = "\n".join([
        f"  - {en} ‚Üí {zh}" 
        for en, zh in list(PM_DICT['common_terms'].items())[:20]
    ])
    
    return f"""‰Ω†ÊòØ‰∏Ä‰ΩçËµÑÊ∑±‰∫ßÂìÅÁªèÁêÜÂÖº‰∏ì‰∏öÊäÄÊúØÁøªËØëÔºåÊã•Êúâ 10 Âπ¥‰ª•‰∏äÁ°ÖË∞∑Âíå‰∏≠ÂõΩ‰∫íËÅîÁΩëÂÖ¨Âè∏ÁöÑ‰∫ßÂìÅÁªèÈ™å„ÄÇ

## ‰ªªÂä°
Â∞Ü‰ª•‰∏ã‰∫ßÂìÅÊñπÊ≥ïËÆ∫ÂÜÖÂÆπÁøªËØëÊàê‰∏ì‰∏öÁ∫ß‰∏≠Êñá„ÄÇËøôÊòØ "{methodology_name}" ÊñπÊ≥ïËÆ∫ÁöÑ {content_type}„ÄÇ

## ÁøªËØëÂéüÂàô
1. **‰∏ì‰∏öÊúØËØ≠**Ôºö‰ΩøÁî®‰∏≠ÂõΩ‰∫ßÂìÅÁªèÁêÜÂúàÂ≠êÂÜÖÁöÑÊ†áÂáÜË°®ËææÔºåËÄåÈùûÊú∫Ê¢∞Áõ¥ËØë
2. **Ëá™ÁÑ∂Ë°®Ëææ**ÔºöËØëÊñáËØªËµ∑Êù•ÂÉèÊòØ‰∏≠ÂõΩ‰∫ßÂìÅÁªèÁêÜÂéüÂàõÁöÑÂÜÖÂÆπÔºåËÄåÈùûÁøªËØëËÖî
3. **‰øùÁïôÁº©ÂÜô**ÔºöÂõΩÈôÖÈÄöÁî®ÊúØËØ≠‰øùÊåÅËã±ÊñáÔºàÂ¶Ç OKR, MVP, PMF, A/B TestÔºâ
4. **‰∏ä‰∏ãÊñáÁêÜËß£**ÔºöÊ†πÊçÆËØ≠Â¢ÉÈÄâÊã©ÊúÄÊÅ∞ÂΩìÁöÑËØëÊ≥ï
5. **ÁÆÄÊ¥Å‰∏ì‰∏ö**ÔºöÈÅøÂÖçÂÜóÈïøÔºå‰ΩøÁî®Á≤æÁÇºÁöÑ‰∏ì‰∏öË°®Ëææ

## ÊúØËØ≠ÂØπÁÖßË°®ÔºàÂøÖÈ°ªÈÅµÂæ™Ôºâ
{terminology_examples}

## ÂæÖÁøªËØëÂÜÖÂÆπ
{content}

## ËæìÂá∫Ë¶ÅÊ±Ç
- Âè™ËæìÂá∫ÁøªËØëÂêéÁöÑ‰∏≠ÊñáÔºå‰∏çË¶Å‰ªª‰ΩïËß£ÈáäÊàñÊ≥®Èáä
- Â¶ÇÊûúÊòØÊï∞ÁªÑÊ†ºÂºèÔºå‰øùÊåÅÁõ∏ÂêåÁöÑÊ†ºÂºèÔºàÊØèË°å‰∏ÄÊù°Ôºâ
- ‰øùÊåÅÂéüÊñáÁöÑÁªìÊûÑÂíåÈÄªËæë
"""

def translate_text(text: str, content_type: str, methodology_name: str) -> str:
    """Call AI API to translate text"""
    if not text or not text.strip():
        return ""
    
    prompt = create_translation_prompt(content_type, text, methodology_name)
    
    try:
        response = client.messages.create(
            model=MODEL,
            max_tokens=4000,
            thinking={
                "type": "enabled",
                "budget_tokens": 2000
            },
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        # Extract text from response (handling thinking blocks)
        for block in response.content:
            if block.type == "text":
                return block.text.strip()
        return ""
    except Exception as e:
        print(f"    ‚ö†Ô∏è Translation error: {e}")
        return ""

def translate_principles(principles: list, methodology_name: str) -> list:
    """Translate a list of principles"""
    if not principles:
        return []
    
    # Combine principles for batch translation
    combined = "\n".join([f"{i+1}. {p}" for i, p in enumerate(principles)])
    translated = translate_text(combined, "Ê†∏ÂøÉÂéüÂàôÂàóË°®", methodology_name)
    
    # Parse back to list
    if translated:
        lines = [line.strip() for line in translated.split('\n') if line.strip()]
        # Remove numbering if present
        result = []
        for line in lines:
            cleaned = re.sub(r'^[\d]+[\.\)]\s*', '', line)
            if cleaned:
                result.append(cleaned)
        return result if result else principles
    return []

def translate_methodology(methodology: dict) -> dict:
    """Translate a single methodology's content to Chinese"""
    name = methodology.get('name', 'Unknown')
    
    # Translate each field
    fields_to_translate = [
        ('summary', 'ÊñπÊ≥ïËÆ∫Ê¶ÇËø∞'),
        ('problemItSolves', 'Ëß£ÂÜ≥ÁöÑÈóÆÈ¢ò'),
        ('whenToUse', 'ÈÄÇÁî®Âú∫ÊôØ'),
        ('commonMistakes', 'Â∏∏ËßÅÈîôËØØ'),
        ('realWorldExample', 'ÁúüÂÆûÊ°à‰æã'),
    ]
    
    for field, desc in fields_to_translate:
        if methodology.get(field):
            translated = translate_text(methodology[field], desc, name)
            if translated:
                methodology[f'{field}_zh'] = translated
                time.sleep(0.5)  # Rate limiting
    
    # Translate principles (array)
    if methodology.get('principles'):
        principles_zh = translate_principles(methodology['principles'], name)
        if principles_zh:
            methodology['principles_zh'] = principles_zh
    
    # Translate name (keep English + add Chinese)
    if name:
        name_zh = translate_text(name, "ÊñπÊ≥ïËÆ∫ÂêçÁß∞", name)
        if name_zh:
            methodology['name_zh'] = f"{name}Ôºà{name_zh}Ôºâ"
    
    # Quote: Keep English original, optionally add Chinese note
    # (Based on user preference to keep quotes in English)
    
    return methodology

def translate_episode(filepath: Path) -> None:
    """Translate an entire episode JSON file"""
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    guest_name = data.get('guest', {}).get('name', 'Unknown')
    methodologies = data.get('methodologies', [])
    
    # Check if already translated
    if methodologies and methodologies[0].get('name_zh'):
        print(f"  ‚è≠Ô∏è Already translated, skipping")
        return
    
    print(f"  üìù Translating {len(methodologies)} methodologies...")
    
    for i, m in enumerate(methodologies):
        method_name = m.get('name', 'Unknown')
        print(f"    [{i+1}/{len(methodologies)}] {method_name}")
        translate_methodology(m)
        time.sleep(1)  # Rate limiting between methodologies
    
    # Translate guest background and episode summary
    if data.get('guest', {}).get('background'):
        bg_zh = translate_text(data['guest']['background'], "ÂòâÂÆæËÉåÊôØ", guest_name)
        if bg_zh:
            data['guest']['background_zh'] = bg_zh
    
    if data.get('episodeSummary'):
        summary_zh = translate_text(data['episodeSummary'], "ËäÇÁõÆÊ¶ÇËø∞", guest_name)
        if summary_zh:
            data['episodeSummary_zh'] = summary_zh
    
    # Save translated data back to file
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"  ‚úÖ Translation complete")

def is_fully_translated(filepath: Path) -> bool:
    """Check if an episode is fully translated (all methodologies have summary_zh)"""
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    methodologies = data.get('methodologies', [])
    if not methodologies:
        return True
    
    # Check if ALL methodologies have summary_zh (the most important field)
    return all(m.get('summary_zh') for m in methodologies)

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Translate InsightHunt episodes to Chinese')
    parser.add_argument('--start', type=int, default=1, help='Starting episode number (1-indexed)')
    parser.add_argument('--count', type=int, default=5, help='Number of episodes to process')
    parser.add_argument('--force', action='store_true', help='Force re-translation even if already done')
    args = parser.parse_args()
    
    print("üåê InsightHunt Chinese Translation")
    print("=" * 50)
    
    # Get all episode files
    files = sorted(DATA_DIR.glob("*.json"))
    total = len(files)
    
    # Calculate batch range
    start_idx = args.start - 1  # 0-indexed
    end_idx = min(start_idx + args.count, total)
    batch_files = files[start_idx:end_idx]
    
    print(f"\nüìä Processing episodes {args.start} to {start_idx + len(batch_files)} of {total}")
    print(f"   Batch size: {len(batch_files)}\n")
    
    translated = 0
    skipped = 0
    
    for i, filepath in enumerate(batch_files):
        guest_name = filepath.stem
        episode_num = start_idx + i + 1
        print(f"[{episode_num}/{total}] Processing: {guest_name}")
        
        # Skip if already translated (unless --force)
        if not args.force and is_fully_translated(filepath):
            print(f"  ‚è≠Ô∏è Already fully translated, skipping")
            skipped += 1
            continue
        
        try:
            translate_episode(filepath)
            translated += 1
        except Exception as e:
            print(f"  ‚ùå Error: {e}")
        
        time.sleep(2)  # Rate limiting between episodes
    
    print("\n" + "=" * 50)
    print(f"‚úÖ Batch complete!")
    print(f"   Translated: {translated}")
    print(f"   Skipped: {skipped}")
    print(f"\nüí° Next batch: python3 scripts/translate_to_chinese.py --start {end_idx + 1} --count {args.count}")

if __name__ == "__main__":
    main()
