#!/usr/bin/env python3
"""
InsightHunt Chinese Translation Script
Translates methodology content to professional PM-quality Chinese
"""

import os
import json
import time
import re
from pathlib import Path
from anthropic import Anthropic

# Configuration
DATA_DIR = Path("data/extracted/json")
DICT_FILE = Path("scripts/pm_terminology_dict.json")

# Use local Anthropic proxy (same as batch_pipeline.py)
client = Anthropic(
    api_key="sk-cbb33b67c7f14a208a67aa705ebf80ee",
    base_url="http://127.0.0.1:8045",
)
MODEL = "gemini-3-pro-high"

# Load PM terminology dictionary
with open(DICT_FILE, 'r', encoding='utf-8') as f:
    PM_DICT = json.load(f)

def create_translation_prompt(content_type: str, content: str, methodology_name: str) -> str:
    """Create a high-quality PM translation prompt"""
    
    terminology_examples = "\n".join([
        f"  - {en} â†’ {zh}" 
        for en, zh in list(PM_DICT['common_terms'].items())[:20]
    ])
    
    return f"""ä½ æ˜¯ä¸€ä½èµ„æ·±äº§å“ç»ç†å…¼ä¸“ä¸šæŠ€æœ¯ç¿»è¯‘ï¼Œæ‹¥æœ‰ 10 å¹´ä»¥ä¸Šç¡…è°·å’Œä¸­å›½äº’è”ç½‘å…¬å¸çš„äº§å“ç»éªŒã€‚

## ä»»åŠ¡
å°†ä»¥ä¸‹äº§å“æ–¹æ³•è®ºå†…å®¹ç¿»è¯‘æˆä¸“ä¸šçº§ä¸­æ–‡ã€‚è¿™æ˜¯ "{methodology_name}" æ–¹æ³•è®ºçš„ {content_type}ã€‚

## ç¿»è¯‘åŸåˆ™
1. **ä¸“ä¸šæœ¯è¯­**ï¼šä½¿ç”¨ä¸­å›½äº§å“ç»ç†åœˆå­å†…çš„æ ‡å‡†è¡¨è¾¾ï¼Œè€Œéæœºæ¢°ç›´è¯‘
2. **è‡ªç„¶è¡¨è¾¾**ï¼šè¯‘æ–‡è¯»èµ·æ¥åƒæ˜¯ä¸­å›½äº§å“ç»ç†åŸåˆ›çš„å†…å®¹ï¼Œè€Œéç¿»è¯‘è…”
3. **ä¿ç•™ç¼©å†™**ï¼šå›½é™…é€šç”¨æœ¯è¯­ä¿æŒè‹±æ–‡ï¼ˆå¦‚ OKR, MVP, PMF, A/B Testï¼‰
4. **ä¸Šä¸‹æ–‡ç†è§£**ï¼šæ ¹æ®è¯­å¢ƒé€‰æ‹©æœ€æ°å½“çš„è¯‘æ³•
5. **ç®€æ´ä¸“ä¸š**ï¼šé¿å…å†—é•¿ï¼Œä½¿ç”¨ç²¾ç‚¼çš„ä¸“ä¸šè¡¨è¾¾

## æœ¯è¯­å¯¹ç…§è¡¨ï¼ˆå¿…é¡»éµå¾ªï¼‰
{terminology_examples}

## å¾…ç¿»è¯‘å†…å®¹
{content}

## è¾“å‡ºè¦æ±‚
- åªè¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Š
- å¦‚æœæ˜¯æ•°ç»„æ ¼å¼ï¼Œä¿æŒç›¸åŒçš„æ ¼å¼ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰
- ä¿æŒåŸæ–‡çš„ç»“æ„å’Œé€»è¾‘
"""

def translate_text(text: str, content_type: str, methodology_name: str) -> str:
    """Call AI API to translate text"""
    if not text or not text.strip():
        return ""
    
    prompt = create_translation_prompt(content_type, text, methodology_name)
    
    try:
        response = client.messages.create(
            model=MODEL,
            max_tokens=4000,
            thinking={
                "type": "enabled",
                "budget_tokens": 2000
            },
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        # Extract text from response (handling thinking blocks)
        for block in response.content:
            if block.type == "text":
                return block.text.strip()
        return ""
    except Exception as e:
        print(f"    âš ï¸ Translation error: {e}")
        return ""

def translate_principles(principles: list, methodology_name: str) -> list:
    """Translate a list of principles"""
    if not principles:
        return []
    
    # Combine principles for batch translation
    combined = "\n".join([f"{i+1}. {p}" for i, p in enumerate(principles)])
    translated = translate_text(combined, "æ ¸å¿ƒåŸåˆ™åˆ—è¡¨", methodology_name)
    
    # Parse back to list
    if translated:
        lines = [line.strip() for line in translated.split('\n') if line.strip()]
        # Remove numbering if present
        result = []
        for line in lines:
            cleaned = re.sub(r'^[\d]+[\.\)]\s*', '', line)
            if cleaned:
                result.append(cleaned)
        return result if result else principles
    return []

def translate_methodology(methodology: dict) -> dict:
    """Translate a single methodology's content to Chinese"""
    name = methodology.get('name', 'Unknown')
    
    # Translate each field
    fields_to_translate = [
        ('summary', 'æ–¹æ³•è®ºæ¦‚è¿°'),
        ('problemItSolves', 'è§£å†³çš„é—®é¢˜'),
        ('whenToUse', 'é€‚ç”¨åœºæ™¯'),
        ('commonMistakes', 'å¸¸è§é”™è¯¯'),
        ('realWorldExample', 'çœŸå®æ¡ˆä¾‹'),
    ]
    
    for field, desc in fields_to_translate:
        if methodology.get(field):
            translated = translate_text(methodology[field], desc, name)
            if translated:
                methodology[f'{field}_zh'] = translated
                time.sleep(0.5)  # Rate limiting
    
    # Translate principles (array)
    if methodology.get('principles'):
        principles_zh = translate_principles(methodology['principles'], name)
        if principles_zh:
            methodology['principles_zh'] = principles_zh
    
    # Translate name (keep English + add Chinese)
    if name:
        name_zh = translate_text(name, "æ–¹æ³•è®ºåç§°", name)
        if name_zh:
            methodology['name_zh'] = f"{name}ï¼ˆ{name_zh}ï¼‰"
    
    # Quote: Keep English original, optionally add Chinese note
    # (Based on user preference to keep quotes in English)
    
    return methodology

def translate_episode(filepath: Path) -> None:
    """Translate an entire episode JSON file"""
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    guest_name = data.get('guest', {}).get('name', 'Unknown')
    methodologies = data.get('methodologies', [])
    
    # Check if already translated
    if methodologies and methodologies[0].get('name_zh'):
        print(f"  â­ï¸ Already translated, skipping")
        return
    
    print(f"  ğŸ“ Translating {len(methodologies)} methodologies...")
    
    for i, m in enumerate(methodologies):
        method_name = m.get('name', 'Unknown')
        print(f"    [{i+1}/{len(methodologies)}] {method_name}")
        translate_methodology(m)
        time.sleep(1)  # Rate limiting between methodologies
    
    # Translate guest background and episode summary
    if data.get('guest', {}).get('background'):
        bg_zh = translate_text(data['guest']['background'], "å˜‰å®¾èƒŒæ™¯", guest_name)
        if bg_zh:
            data['guest']['background_zh'] = bg_zh
    
    if data.get('episodeSummary'):
        summary_zh = translate_text(data['episodeSummary'], "èŠ‚ç›®æ¦‚è¿°", guest_name)
        if summary_zh:
            data['episodeSummary_zh'] = summary_zh
    
    # Save translated data back to file
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"  âœ… Translation complete")

def main():
    print("ğŸŒ InsightHunt Chinese Translation")
    print("=" * 50)
    
    # Get all episode files
    files = sorted(DATA_DIR.glob("*.json"))
    print(f"\nğŸ“Š Found {len(files)} episodes to translate\n")
    
    for i, filepath in enumerate(files):
        guest_name = filepath.stem
        print(f"[{i+1}/{len(files)}] Processing: {guest_name}")
        
        try:
            translate_episode(filepath)
        except Exception as e:
            print(f"  âŒ Error: {e}")
        
        time.sleep(2)  # Rate limiting between episodes
    
    print("\n" + "=" * 50)
    print("âœ… Translation complete!")
    print(f"ğŸ“Š Translated {len(files)} episodes")

if __name__ == "__main__":
    main()
